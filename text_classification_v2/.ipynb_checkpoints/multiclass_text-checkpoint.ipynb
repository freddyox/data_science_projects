{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "The problem description may be seen <a href=\"https://www.hackerrank.com/challenges/document-classification/problem\">here</a> and may be summarized as follows:\n",
    "1. We have a stack of preprocessed documents, and our task is to assign the documents to a category, labeled 1 through 8 inclusive.\n",
    "2. We are given training data which includes the correct classification number and some sample text.\n",
    "3. We will use the natural language tool kit, specifically PorterStemmer, to do the text processing. The text feature extraction is handled using Tf-idf term weighting (term-frequency inverse document frequency), which allows us to weight common words such as \"a\", \"is\", etc. less.\n",
    "\n",
    "## Summary\n",
    "Linear support vector machine algorithm yields an accuracy of roughly 97% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "train_df = pd.read_csv('train.txt', delimiter='\\t')\n",
    "test_df = pd.read_csv('test.txt', header = None, delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape = (5484, 2) \n",
      "Testing shape = (2189, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape =\", train_df.shape, \"\\nTesting shape =\", \n",
    "      test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from u s japan rif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china daily says vermin eat pct grain stocks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sumitomo bank aims at quick recovery from merg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amatil proposes two for five bonus share issue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  asian exporters fear damage from u s japan rif...\n",
       "1  china daily says vermin eat pct grain stocks a...\n",
       "2  australian foreign ship ban ends but nsw ports...\n",
       "3  sumitomo bank aims at quick recovery from merg...\n",
       "4  amatil proposes two for five bonus share issue..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naming the columns in train and test set\n",
    "train_df.columns = [\"label\",\"text\"]\n",
    "test_df.columns = [\"text\"]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use Porter Stemmer natural language tk\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    \"\"\"Perform the word stemming\"\"\"\n",
    "    stemmed_text = []\n",
    "    for item in tokens:\n",
    "        stemmed_text.append(stemmer.stem(item))\n",
    "    return stemmed_text\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize the text, remove any non-word characters\"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = text.split(\" \")\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7673, 1100)\n"
     ]
    }
   ],
   "source": [
    "# Text feature extraction:\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\\\n",
    "                             tokenizer=tokenize,\\\n",
    "                             ngram_range=(1,3),\\\n",
    "                             lowercase=True,\\\n",
    "                             stop_words ='english',\\\n",
    "                             max_features =1100)\n",
    "\n",
    "vectorized_features = vectorizer.fit_transform(train_df.text.tolist() + test_df.text.tolist())\n",
    "\n",
    "#Convert the document term matrix to numpy nd array\n",
    "vectorized_features_nd = (vectorized_features.toarray())\n",
    "print (vectorized_features_nd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models:\n",
    "clf = LinearSVC(penalty = 'l2', dual = True, C=1.0, loss='hinge')\n",
    "#clf = KNeighborsClassifier()\n",
    "#clf = MultinomialNB()\n",
    "#clf = RandomForestClassifier(n_estimators=20, n_jobs=-1, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of validation set: 97.174%\n",
      "accuracy of test set: 97.396%\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "X_train = vectorized_features_nd[0:len(train_df)]\n",
    "Y_train = train_df.label\n",
    "X_test = vectorized_features_nd[len(train_df):]\n",
    "\n",
    "# split in to train and test set\n",
    "txt_train, txt_valid, label_train, label_valid = \\\n",
    "    train_test_split(X_train, Y_train, test_size=0.2, random_state=5)\n",
    "\n",
    "#print (len(txt_train), len(txt_valid), len(txt_train) + len(txt_valid))\n",
    "\n",
    "# Fit model to train subset and predict on validation set\n",
    "clf = clf.fit(txt_train,label_train)\n",
    "pred_valid = clf.predict(txt_valid)\n",
    "score = accuracy_score(label_valid, pred_valid)*100.0\n",
    "print ('accuracy of validation set: %1.3f%%' % score)\n",
    "\n",
    "label_test = []\n",
    "\n",
    "# read true labels from file\n",
    "foput = open(\"test_labels.txt\",\"r\")\n",
    "for m in foput :\n",
    "    m = str(m).strip()\n",
    "    label_test.append(int(m))\n",
    "\n",
    "# fit entire training set and make prediction on test set\n",
    "clf = clf.fit(X_train,Y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "score = accuracy_score(label_test, pred_test)*100.0\n",
    "print ('accuracy of test set: %1.3f%%' % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
